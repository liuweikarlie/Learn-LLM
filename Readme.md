# Readme

## RAG folder explain
- `embedding.py` is for split the text and then convert it to embedding format, store it in vector database
- `CustomLLM.py` is load the LLM for langchain use
- `RAG.py` --> RAG framework (called the CustomLLM)
- `Frontend.py` ---> frontend webside to load the model and interact

## Data folder 
check the data folder readme

## load_model folder
- you should download the llama.cpp
- get the gguf model
- check the load_model folder readme


# Reading
- [数学计算+ReAct](https://github.com/EvilPsyCHo/Play-with-LLMs/blob/main/examples/llama3-8b-Instruct-ReAct-Agent-advanced.ipynb)
- [translate agent （Reflection）- Andrew Ng 做的，看了好像并不太难，用的chatgpt，但是听说会很慢](https://github.com/andrewyng/translation-agent)
  
