# Readme

## RAG folder explain
- embedding.py is for split the text and then convert it to embedding format, store it in vector database
- CustomLLM.py is load the LLM for langchain use
- RAG.py --> RAG framework (called the CustomLLM)
- Frontend.py ---> frontend webside to load the model and interact

## Data folder 
check the data folder readme

## load_model folder
- you should download the llama.cpp
- get the gguf model
- check the load_model folder readme


