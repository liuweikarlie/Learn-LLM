# Readme

## RAG folder
- embedding.py is for split the text and then convert it to embedding format, store it in vector database
- CustomLLM.py is load the LLM for langchain use
- RAG.py --> RAG framework (called the CustomLLM)
- Frontend.py ---> frontend webside to load the model and interact

## Data folder (load the forecast H share pipeline)

## load_model folder
-> you should download the llama.cpp  
-> get the gguf model


